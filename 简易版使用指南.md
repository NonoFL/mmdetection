##### 若设置自己的数据集，建议准备COCO格式的数据集。以SSDD数据集为例子，4个改动地方：
    1. 新建 /config/datasets/ssdd_detection.py ，copy coco_detection.py, 改动 data_root, dataset_type, img_norm_cfg, ann_file, img_prefix
    2. 新建 /mmdet/datasets/ssdd.py, copy coco.py, 改动 CLASSES
    3. 向 /mmdet/core/evaluation/class_names.py 添加数据集对应的分类名称
    4. 向 /mmdet/datasets/__init__.py 导入对应数据集类，并添加到list中。

##### 参数改变
    学习率：对应配置文件的optimizer中
        调整方法：默认：    8gpu*2img/gpu:0.02
                线性原则： 1gpu*ximg/gpu：0.002/8/2*x
                有：      1gpu*8img/gpu:0.01
                有：      1gpu*16img/gpu:0.02
                         

    epoch：/congfig/_base_/schedule_1x.py，max_epochs,其中，schedule_2x.py的epoch是schedule_1x.py的两倍
    train_val_iter: 
    batch size：/config/datasets/ssdd_detection.py中

##### Train
    单机单卡： python tools/train.py ${CONFIG_FILE} [optional arguments]
    单机多卡： ./tools/dist_train.sh ${CONFIG_FILE} ${GPU_NUM} [optional arguments] 
            （./tools/dist_train.sh configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py 2）在2张gpu训练

##### Test
    # single-gpu testing    [说明](mmdetection/docs/1_exist_data_model.md)
    python tools/test.py ${CONFIG_FILE} ${CHECKPOINT_FILE} [--out ${RESULT_FILE}] [--eval ${EVAL_METRICS}] [--show]

    # multi-gpu testing
    ./tools/dist_test.sh ${CONFIG_FILE} ${CHECKPOINT_FILE} ${GPU_NUM} [--out ${RESULT_FILE}] [--eval ${EVAL_METRICS}]

##### 工具
    1. 测试一张图片：python demo/image_demo.py ${IMAGE_FILE} ${CONFIG_FILE} ${CHECKPOINT_FILE} [--device ${GPU_ID}] [--score-thr ${SCORE_THR}]
    
                eg：
                    python demo/image_demo.py demo/demo.jpg configs/faster_rcnn_r50_fpn_1x_coco.py \
                    checkpoints/ faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth --device cpu

    2. 分析loss/mAP:python tools/analyze_logs.py plot_curve [--keys ${KEYS}] [--title ${TITLE}] [--legend ${LEGEND}] [--backend ${BACKEND}] [--style ${STYLE}] [--out ${OUT_FILE}]

                eg：2.1 画出某次运行时的classification loss：
                    python tools/analyze_logs.py plot_curve log.json --keys loss_cls --legend loss_cls
                    2.2 画出... 的... 和regression loss，并保存到pdf：
                    python tools/analyze_logs.py plot_curve log.json --keys loss_cls loss_bbox --out losses.pdf
                    2.3 比较两次运行在同一张图片中的bbox mAP：
                    python tools/analyze_logs.py plot_curve log1.json log2.json --keys bbox_mAP --legend run1 run2
                    2.4 计算平均训练速度：
                    python tools/analyze_logs.py cal_train_time log.json [--include-outliers]

                注：
                    首次使用：pip install seaborn
                    需给定 training log.json file
    
    3. 计算FLOPs和Params:python tools/get_flops.py ${CONFIG_FILE} [--shape ${INPUT_SHAPE}]

    4. 发布模型：python tools/publish_model.py ${INPUT_FILENAME} ${OUTPUT_FILENAME}

                eg：python tools/publish_model.py work_dirs/faster_rcnn/latest.pth faster_rcnn_r50_fpn_1x_20190801.pth



##### 另：
        1.  workflow = [('train', 1)]，： train workflow，也就是迭代训练
            workflow = [('train', n),('val', 1)]：先进行 n 个 epoch 的训练，后再进行1个 epoch 的验证，然后循环往复,
            workflow = [('val', 1),('train', n)] 表示先进行验证，然后才开始训练     

        2.  out_indices = (0,1,2,3):表示输出的特征图索引为（0，1，2，3）
            ResNet的骨架范式：stem + n stage + cls head，实际为 stem -> 4个stage ->cls head
            stem的输出stride为4， 4个stage的输出stride为 4， 8， 16， 32， 这4个输出就对应out_indices的索引
            eg：想要输出stride=4的特征图， out_indices = (0,)
                ...       =4和16  .... ，  out_indices = (0, 2) 

        3.  frozen_stages:
            frozen_stages=-1，表示全部可学习
            frozen_stage=0，表示stem权重固定
            frozen_stages=1，表示 stem 和第一个 stage 权重固定
            frozen_stages=2，表示 stem 和前两个 stage 权重固定
            ...
            (注意：若想重写backbone类，参考ResNet中train函数。防止运行的时候算法重新进入train模式导致BN没有固定住)

        4.  norm_cfg ， norm_eval:
            norm_cfg = dict(type='BN',requires_grad=True),表示采用的归一化算子，type为BN或GN，requires_grads 表示算子是否需要梯度，是否更新
            norm_eval：用于控制整个骨架网络的归一化算子是否要变成eval模式 






