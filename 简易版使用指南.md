跑程序：
    atss
    autoassign
    centernet
    cornernet
    dcn
    ssd
    yolox
    
    









##### 若设置自己的数据集，建议准备COCO格式的数据集。以SSDD数据集为例子，4个改动地方：
    1. 新建 /config/datasets/ssdd_detection.py ，copy coco_detection.py, 改动 data_root, dataset_type, img_norm_cfg, ann_file, img_prefix
    2. 新建 /mmdet/datasets/ssdd.py, copy coco.py, 改动 CLASSES
    3. 向 /mmdet/core/evaluation/class_names.py 添加数据集对应的分类名称
    4. 向 /mmdet/datasets/__init__.py 导入对应数据集类，并添加到list中。

##### 参数改变
    学习率：对应配置文件的optimizer中
        调整方法：默认：    8gpu*2img/gpu:0.02
                线性原则： 1gpu*ximg/gpu：0.002/8/2*x
                有：      1gpu*8img/gpu:0.01
                有：      1gpu*16img/gpu:0.02
                         

    epoch：/congfig/_base_/schedule_1x.py，max_epochs,其中，schedule_2x.py的epoch是schedule_1x.py的两倍
    train_val_iter: 
    batch size：/config/datasets/ssdd_detection.py中

##### Train
    单机单卡： python tools/train.py ${CONFIG_FILE} [optional arguments]
    单机多卡： ./tools/dist_train.sh ${CONFIG_FILE} ${GPU_NUM} [optional arguments] 
            （./tools/dist_train.sh configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py 2）在2张gpu训练

##### Test
    # single-gpu testing    [说明](mmdetection/docs/1_exist_data_model.md)
    python tools/test.py ${CONFIG_FILE} ${CHECKPOINT_FILE} [--out ${RESULT_FILE}] [--eval ${EVAL_METRICS}] [--show]

    # multi-gpu testing
    ./tools/dist_test.sh ${CONFIG_FILE} ${CHECKPOINT_FILE} ${GPU_NUM} [--out ${RESULT_FILE}] [--eval ${EVAL_METRICS}]

##### 工具
    1. 测试一张图片：python demo/image_demo.py ${IMAGE_FILE} ${CONFIG_FILE} ${CHECKPOINT_FILE} [--device ${GPU_ID}] [--score-thr ${SCORE_THR}]
    
                eg：
                    python demo/image_demo.py demo/demo.jpg configs/faster_rcnn_r50_fpn_1x_coco.py \
                    checkpoints/ faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth --device cpu

    2. 分析loss/mAP:python tools/analyze_logs.py plot_curve [--keys ${KEYS}] [--title ${TITLE}] [--legend ${LEGEND}] [--backend ${BACKEND}] [--style ${STYLE}] [--out ${OUT_FILE}]

                eg：2.1 画出某次运行时的classification loss：
                    python tools/analyze_logs.py plot_curve log.json --keys loss_cls --legend loss_cls
                    2.2 画出... 的... 和regression loss，并保存到pdf：
                    python tools/analyze_logs.py plot_curve log.json --keys loss_cls loss_bbox --out losses.pdf
                    2.3 比较两次运行在同一张图片中的bbox mAP：
                    python tools/analyze_logs.py plot_curve log1.json log2.json --keys bbox_mAP --legend run1 run2
                    2.4 计算平均训练速度：
                    python tools/analyze_logs.py cal_train_time log.json [--include-outliers]

                注：
                    首次使用：pip install seaborn
                    需给定 training log.json file
    
    3. 计算FLOPs和Params:python tools/get_flops.py ${CONFIG_FILE} [--shape ${INPUT_SHAPE}]

    4. 发布模型：python tools/publish_model.py ${INPUT_FILENAME} ${OUTPUT_FILENAME}

                eg：python tools/publish_model.py work_dirs/faster_rcnn/latest.pth faster_rcnn_r50_fpn_1x_20190801.pth


